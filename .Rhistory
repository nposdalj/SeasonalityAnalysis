q()
#load libraries
#define the lat and long of interest
#loading sperm whale data
site = 'Wake'
saveDir = paste("D:/My Drive/CentralPac_TPWS_metadataReduced/Wake/Seasonality/")#setting the directory
#load data from StatisicalAnalysis_All
filenameStatAll = paste(saveDir,site,"_GroupedDay.csv",sep="")
GroupedDay = read.csv(filenameStatAll) #load files as data frame
#loading the environmental data
envDir = paste("D:/My Drive/Gaia_EnvironmentalData/CentralPac/")#setting the directory
filenameStatAll = paste(envDir,"Chlorophyll.csv",sep="")#load files as data frame
chl = read.csv(filenameStatAll)
#subset the dataframe based on the area of interest
#average the environmental variable based on the ITS over the area of interest
#save standard deviation
#merge the data sets
#run GAM
#plot GAMs
#load libraries
library(ncdf4)
install.packages("ncdf4")
#load libraries
library(ncdf4)
#SSH anomaly data
filenameStatAll = paste(envDir,"SSHAnomaly.nc",sep="")#load files as data frame
SSH = nc_open(filenameStatAll)
View(SSH)
View(SSH)
names(SSH$var)
v1=SSH$var[[1]]
View(v1)
SSHvar=ncvar_get(SSH,v1)
View(SSH)
SSHvar
SSH_lon=v1$dim[[1]]$vals
SSH_lat=v1$dim[[2]]$vals
SSH_lat
SSH_lon
SSHvar
#load libraries
library(ncdf4)
#define the lat and long of interest
#loading sperm whale data
site = 'Wake'
saveDir = paste("D:/My Drive/CentralPac_TPWS_metadataReduced/Wake/Seasonality/")#setting the directory
#load data from StatisicalAnalysis_All
filenameStatAll = paste(saveDir,site,"_GroupedDay.csv",sep="")
GroupedDay = read.csv(filenameStatAll) #load files as data frame
#load sex specific data
#loading the environmental data
envDir = paste("D:/My Drive/Gaia_EnvironmentalData/CentralPac/")#setting the directory
#chlorophyll data
filenameStatAll = paste(envDir,"Chlorophyll.csv",sep="")#load files as data frame
chl = read.csv(filenameStatAll)
#subset the dataframe based on the area of interest
#average the environmental variable based on the ITS over the area of interest
#save standard deviation
#SSH anomaly data
filenameStatAll = paste(envDir,"SSHAnomaly.nc",sep="")#load files as data frame
SSH = nc_open(filenameStatAll)
names(SSH$var)
v1=SSH$var[[1]]
SSHvar=ncvar_get(SSH,v1)
SSH_lon=v1$dim[[1]]$vals
SSH_lat=v1$dim[[2]]$vals
library(geepack)         # for the GEEs (Wald's hypothesis tests allowed)
library(splines)         # to construct the B-splines within a GEE-GLM
library(tidyverse)       # because it literally does everything
library(rjags)           # replacement for geeglm which is out of date
library(ROCR)            # to build the ROC curve
library(PresenceAbsence) # to build the confusion matrix
library(ggplot2)         # to build the partial residual plots
library(mvtnorm)         # to build the partial residual plots
library(gridExtra)       # to build the partial residual plots
library(SimDesign)
library(lubridate)
library(regclass)
library(mgcv)
site = 'CB'
dir = paste("D:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/All_Sites")
fileName = paste("D:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/All_Sites/AllSitesGrouped_Binary_GAMGEE_ROW.csv")#setting the directory
HourTable = read.csv(fileName)
HourTable = na.omit(HourTable)
HourTable$date = as.Date(HourTable$tbin)
HourTable$tbin = as.POSIXct(HourTable$tbin)
HourTable = HourTable[ order(HourTable$tbin , decreasing = FALSE ),]
SiteHourTable = dplyr::filter(HourTable, grepl(site,Site))
SiteHourTable$Hour = hour(SiteHourTable$tbin)
fileName2 = paste("I:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/All_Sites/AllSitesGrouped_GAMGEE_ROW.csv")#setting the directory
DayTable = read.csv(fileName2) #no effort days deleted
DayTable = na.omit(DayTable)
DayTable$tbin = as.Date(DayTable$tbin)
SiteDayTable = dplyr::filter(DayTable,grepl(site,Site))
#Daily data - for block calculations using the Merkens method
fileName2 = paste("D:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/All_Sites/AllSitesGrouped_GAMGEE_ROW.csv")#setting the directory
DayTable = read.csv(fileName2) #no effort days deleted
DayTable = na.omit(DayTable)
DayTable$tbin = as.Date(DayTable$tbin)
SiteDayTable = dplyr::filter(DayTable,grepl(site,Site))
startDate = SiteDayTable$tbin[1]
endDate = SiteDayTable$tbin[nrow(SiteDayTable)]
timeseries = data.frame(date=seq(startDate, endDate, by="days"))
timeseries$one = 1:nrow(timeseries)
oneday = left_join(SiteHourTable,timeseries,by="date")
onedaygrouped = aggregate(oneday[, c(2,8)], list(oneday$one), mean)
onedaygrouped$Group.1 = as.factor(onedaygrouped$Group.1)
onedaygrouped = onedaygrouped %>% mutate_if(is.numeric, ~1 * (. != 0))
acf(onedaygrouped$PreAbs, plot = FALSE)
acf(onedaygrouped$PreAbs, lag.max=70)
acf(onedaygrouped$PreAbs, lag.max=70, ylim=c(0,0.1), xlim =c(55,65))
timeseries$one = NULL
#CB lag
thirtyfour = rep(1:(floor(nrow(timeseries)/34)), times=1, each=34)
timeseries$thirtyfour = c(thirtyfour, thirtyfour[714]+1,thirtyfour[714]+1,thirtyfour[714]+1,
thirtyfour[714]+1,thirtyfour[714]+1,thirtyfour[714]+1,thirtyfour[714]+1)
HourTableBinned = left_join(SiteHourTable,timeseries,by = "date")
HourTableBinned = HourTableBinned[ order(HourTableBinned$tbin , decreasing = FALSE ),]
GLM1 = glm(PreAbs ~ Julian + Hour, family = binomial, data = SiteHourTable)
GLM1_CB = glm(PreAbs ~ Julian + Hour + Year, family = binomial, data = SiteHourTable)
#VIF scores in GLM to work out collinearity:
VIF(GLM1)
VIF(GLM1_CB)
AvgDayBasis <- gam(PreAbs~s(Julian, bs ="cc", k=-1), fit=F, data = SiteHourTable, family =binomial, knots = list(HOUR=seq(0,23,length=6)))$X[,2:5]
AvgDayMat = as.matrix(AvgDayBasis)
#DATENO
POD0a = geeglm(PreAbs ~ bs(Julian, knots=10), family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
POD0b = geeglm(PreAbs ~ AvgDayMat, family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
model0A<-c("POD0", "POD0a", "POD0b")
QIC0A<-c(QIC(POD0)[1],QIC(POD0a)[1],QIC(POD0b)[1])
QICmod0A<-data.frame(rbind(model0A,QIC0A))
QICmod0A
POD0<-geeglm(PreAbs ~ 1, family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
model0A<-c("POD0", "POD0a", "POD0b")
QIC0A<-c(QIC(POD0)[1],QIC(POD0a)[1],QIC(POD0b)[1])
QICmod0A<-data.frame(rbind(model0A,QIC0A))
QICmod0A
POD1a = geeglm(PreAbs ~ as.factor(Year), family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
POD1b = geeglm(PreAbs ~ Year, family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
POD1c = geeglm(PreAbs ~ bs(Year), family = binomial, corstr="ar1", id=thirtyfour, data=HourTableBinned)
model1A<-c("POD0", "POD1a", "POD1b","POD1c")
QIC1A<-c(QIC(POD0)[1],QIC(POD1a)[1],QIC(POD1b)[1],QIC(POD1c)[1])
QICmod1A<-data.frame(rbind(model1A,QIC1A))
QICmod1A
POD2a = geeglm(PreAbs ~ AvgDayMat+bs(Year),family = binomial, corstr="independence", id=thirtyfour, data=HourTableBinned)
#without AvgDayMat
POD2b = geeglm(PreAbs ~ bs(Year),family = binomial, corstr="independence", id=thirtyfour, data=HourTableBinned)
#without Year
POD2c = geeglm(PreAbs ~ AvgDayMat,family = binomial, corstr="independence", id=thirtyfour, data=HourTableBinned)
model2A = c("POD0","POD2a","POD2b","POD2c")
QIC2A = c(QIC(POD0)[1],QIC(POD2a)[1],QIC(POD2b)[1],QIC(POD2c)[1])
QICmod2A<-data.frame(rbind(model2A,QIC2A))
QICmod2A
#QIC            QIC.1            QIC.2            QIC.3
#model2A            POD0            POD2a            POD2b            POD2c
#QIC2A   62707.622017871 59362.4453354621 61587.2259674017 60383.6808219463
# STEP 6: Testing covariate significance.
# At this point, the resulting model is fitted using the library geeglm. The order in which the covariates enter the model is determined by the QIC score
# (the ones that, if removed, determine the biggest increase in QIC enter the model first).
#In descending order:
#AvgDayMat
#Year
POD3 = geeglm(PreAbs ~ AvgDayMat+bs(Year),family = binomial, corstr="independence", id=thirtyfour, data=HourTableBinned)
anova(POD3)
#CB
#Analysis of 'Wald statistic' Table
#Model: binomial, link: logit
#Response: PreAbs
#Terms added sequentially (first to last)
#Df     X2 P(>|Chi|)
#AvgDayMat  4 37.059 1.752e-07 ***
#bs(Year)   3 21.683 7.594e-05 ***
#---
#Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# Retain all covariates. This is the final model.
#Step 7: Construction of the ROC curve
# STEP 6: Construction of the ROC curve
pr <- predict(POD3, type="response")
pred <- prediction(pr,SiteHourTable$PreAbs)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, colorize=TRUE, print.cutoffs.at=c(0.1,0.2,0.3,0.4,0.5))
#This creates a ROC plot
View(AvgDayMat)
View(AvgDayBasis)
View(AvgDayBasis)
View(AvgDayMat)
View(AvgDayBasis)
View(AvgDayMat)
View(AvgDayMat)
View(AvgDayBasis)
View(AvgDayMat)
View(DayTable)
View(HourTable)
acf(residuals(POD03))
acf(residuals(GLM1_CB))
acf(residuals(GLM1_CB),lag.max=100)
acf(residuals(GLM1_CB),lag.max=1500)
acf(residuals(GLM1_CB),lag.max=1500, xlim=c(900,1000))
acf(residuals(GLM1_CB),lag.max=1500, ylim=c(0,0.1),xlim=c(900,1000))
anova(GLM1_CB)
library(car)
Anova(GLM1_CB)
## STEP 4: Model selection - covariate preparation ##
# Construct variance-covariance matrices for cyclic covariates:
AvgDayBasis <- gam(PreAbs~s(Julian, bs ="cc", k=-1), fit=F, data = SiteHourTable, family =binomial, knots = list(Julian=seq(1,365,length=6)))$X[,2:5]
library(mgcv)
## STEP 4: Model selection - covariate preparation ##
# Construct variance-covariance matrices for cyclic covariates:
AvgDayBasis <- gam(PreAbs~s(Julian, bs ="cc", k=-1), fit=F, data = SiteHourTable, family =binomial, knots = list(Julian=seq(1,365,length=6)))$X[,2:5]
## STEP 4: Model selection - covariate preparation ##
# Construct variance-covariance matrices for cyclic covariates:
AvgDayBasis <- gam(PreAbs~s(Julian, bs ="cc", k=4), fit=F, data = SiteHourTable, family =binomial, knots = list(Julian=seq(1,365,length=6)))$X[,2:5]
## STEP 4: Model selection - covariate preparation ##
# Construct variance-covariance matrices for cyclic covariates:
AvgDayBasis <- gam(PreAbs~s(Julian, bs ="cc", k=6), fit=F, data = SiteHourTable, family =binomial, knots = list(Julian=seq(1,365,length=6)))$X[,2:5]
AvgDayMat = as.matrix(AvgDayBasis)
#load libraries
library(boot)
library(pracma)
library(geepack)         # for the GEEs (Wald's hypothesis tests allowed)
library(splines)         # to construct the B-splines within a GEE-GLM
library(tidyverse)       # because it literally does everything
library(rjags)           # replacement for geeglm which is out of date
library(ROCR)            # to build the ROC curve
library(PresenceAbsence) # to build the confusion matrix
library(ggplot2)         # to build the partial residual plots
library(mvtnorm)         # to build the partial residual plots
library(gridExtra)       # to build the partial residual plots
library(SimDesign)
library(lubridate)
library(regclass)
library(mgcv)
library(ChemoSpecUtils)
library(car)            # to run an ANOVA
library(splines2)       # to use mSpline for the GEEs
#load functions
source('C:/Users/Alba/Documents/GitHub/SeasonalityAnalysis/GAM_GEEs/GAMGEE_Plotting_Functions.R')
site = 'PT'
saveWorkspace = paste("D:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/",site,'/',sep="")
fileName = paste(saveWorkspace,site,'_SiteSpecific_gamgeeOutput.RData',sep="")
load(fileName)
saveDir = paste("D:/My Drive/GofAK_TPWS_metadataReduced/Plots/",site,'/',sep="")
ggPlot_JD(PODFinal,SiteHourTableB,site)
#load libraries
library(boot)
library(pracma)
library(geepack)         # for the GEEs (Wald's hypothesis tests allowed)
library(splines)         # to construct the B-splines within a GEE-GLM
library(tidyverse)       # because it literally does everything
library(rjags)           # replacement for geeglm which is out of date
library(ROCR)            # to build the ROC curve
library(PresenceAbsence) # to build the confusion matrix
library(ggplot2)         # to build the partial residual plots
library(mvtnorm)         # to build the partial residual plots
library(gridExtra)       # to build the partial residual plots
library(SimDesign)
library(lubridate)
library(regclass)
library(mgcv)
library(ChemoSpecUtils)
library(car)            # to run an ANOVA
library(splines2)       # to use mSpline for the GEEs
#load functions
source('C:/Users/Alba/Documents/GitHub/SeasonalityAnalysis/GAM_GEEs/GAMGEE_Plotting_Functions.R')
# Load Workspace --------------------------------------------------
site = 'QN'
saveWorkspace = paste("D:/My Drive/GofAK_TPWS_metadataReduced/SeasonalityAnalysis/",site,'/',sep="")
fileName = paste(saveWorkspace,site,'_SiteSpecific_gamgeeOutput.RData',sep="")
load(fileName)
saveDir = paste("D:/My Drive/GofAK_TPWS_metadataReduced/Plots/",site,'/',sep="")
# Plot Julian Day ---------------------------------------------------------
if (site == 'CB'){
BasePlot_JD_Year(PODFinal,SiteHourTableB)
ggPlot_JD_Year(PODFinal, SiteHourTableB)
} else {
BasePlot_JD(PODFinal,SiteHourTableB)
ggPlot_JD(PODFinal,SiteHourTableB,site)
}
# Plot Year ---------------------------------------------------------------
if (site == 'CB'){
ggPlot_Year(PODFinal,SiteHourTableB)
}
setwd("~/GitHub/SeasonalityAnalysis")
# Libraries
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
library(ggplot2)
library(dplyr)
library(forcats)
library(ggpubr)
library(plyr)
library(anytime)
library(fANCOVA)
library(tweedie)
library(car)
library(locfit)
library(MuMIn)
library(tidyverse)
library(mgcv)
library(ggpubr)
library(mgcViz)
library(cplm)
library(statmod)
library(gee)
library(geepack)
library(TSA)
library(epitools)
library(lubridate)
library(survival)
library(gtable)
#load data from MATLAB
site = 'BS'
saveDir = paste("H:/My Drive/WAT_TPWS_metadataReduced/SeasonalityAnalysis/BS/")
filename = paste(saveDir,site,"_binPresence.csv",sep="")
binPresence = read.csv(filename) #no effort days deleted
head(binPresence)
str(binPresence)
binPresence$Season = as.factor(binPresence$Season) #change season from an integer to a factor
levels(binPresence$Season)
binPresence$Season = revalue(binPresence$Season, c("1"="Summer", "2"="Fall", "3"="Winter", "4"="Spring")) #change the numbers in actual seasons
binPresence$tbin = anytime(as.factor(binPresence$tbin))
#load data from StatisticalAnalysis_Gender: Females
filenameStatGender_F = paste(saveDir,site,"_GroupedDayF.csv",sep="")
GroupedDayF = read.csv(filenameStatGender_F) #no effort days deleted
#load data from StatisticalAnalysis_Gender: Juveniles
filenameStatGender_J= paste(saveDir,site,"_GroupedDayJ.csv",sep="")
GroupedDayJ = read.csv(filenameStatGender_J) #no effort days deleted
#load data from StatisticalAnalysis_Gender: Males
filenameStatGender_M = paste(saveDir,site,"_GroupedDayM.csv",sep="")
GroupedDayM = read.csv(filenameStatGender_M) #no effort days deleted
#plot data as proportion of hours per day with clicks
title1 = paste(site,"Proprtion of Hours/Day w/ Clicks")
plot1 = ggplot(binPresence, aes(x=tbin,y=FeHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot2 = ggplot(binPresence, aes(x=tbin,y=JuHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot3 = ggplot(binPresence, aes(x=tbin,y=MaHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "),align = "v",ncol = 1, nrow = 3)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 14), bottom = text_grob("Time (years)"),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90))
fig1 =paste(saveDir,site,site,"HoursProp_TimeSeries_StackedGroups.png",sep="")
ggsave(fig1)
#plot data as box plot for seasons; have to plot this with no effort days deleted
title2 = paste("Seasonal Presence at",site)
plot1 = ggplot(binPresence, aes(x=Season, y=FeHoursProp, color = Season))+
geom_boxplot()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())+
scale_color_brewer(palette = "Dark2")
plot2 = ggplot(binPresence, aes(x=Season, y=JuHoursProp, color = Season))+
geom_boxplot()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())+
scale_color_brewer(palette = "Dark2")
plot3 = ggplot(binPresence, aes(x=Season, y=MaHoursProp, color = Season))+
geom_boxplot()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())+
scale_color_brewer(palette = "Dark2")
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "), align = "hv", ncol = 1, nrow = 3, legend = "right",common.legend = TRUE)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 14), bottom = text_grob("Seasons"),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90))
fig2 =paste(saveDir,site,"BoxPlot_StackedGroups.png",sep="")
ggsave(fig2)
#plot data grouped with ITS as proportion of hours per day with clicks
title1 = paste(site,"Proprtion of Hours/Day w/ Clicks - ITS")
theme(axis.text=element_text(size=18),
axis.title=element_text(size=20,face="bold"))
title1 = paste("Proportion of Hours per Day with Clicks at Buldir Island, BSAI")
plot1 = ggplot(GroupedDayF, aes(x=tbin,y=FeHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank(),axis.text=element_text(size=18))+
theme(axis.title.y = element_blank(),axis.text=element_text(size=18))
plot2 = ggplot(GroupedDayJ, aes(x=tbin,y=JuHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank(),axis.text=element_text(size=18))+
theme(axis.title.y = element_blank(),axis.text=element_text(size=18))
plot3 = ggplot(GroupedDayM, aes(x=tbin,y=MaHoursProp))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank(),axis.text=element_text(size=18))+
theme(axis.title.y = element_blank(),axis.text=element_text(size=18))
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "),align = "v",ncol = 1, nrow = 3)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 20), bottom = text_grob("Time (years)", size = 20),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90, size = 24))
fig1 =paste(saveDir,site,"HoursProp_TimeSeriesITS_StackedGroups.png",sep="")
ggsave(fig1)
##### grouped data by day of year - mean
filename2 = paste(saveDir,site,"_365GroupedMean.csv",sep="")
oneyear = read.csv(filename2)
filenameGYF = paste(saveDir,site,"_GroupedYearF.csv",sep="")
GroupedYearF = read.csv(filenameGYF)
filenameGYJ = paste(saveDir,site,"_GroupedYearJ.csv",sep="")
GroupedYearJ = read.csv(filenameGYJ)
filenameGYM = paste(saveDir,site,"_GroupedYearM.csv",sep="")
GroupedYearM = read.csv(filenameGYM)
#plot data as time series
#plot data as proportion of hours per day with clicks
if (exists('oneyearF')){
title3 = paste(site,"Yearly Average of Proportion of Hours per Day with Clicks - Time Series")
plot1 = ggplot(oneyearF, aes(x=Day,y=HoursPropFE))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot2 = ggplot(oneyearJ, aes(x=Day,y=HoursPropJU))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot3 = ggplot(oneyearM, aes(x=Day,y=HoursPropMA))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "),align = "v",ncol = 1, nrow = 3)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 14), bottom = text_grob("Time (years)"),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90))
fig1 = paste(saveDir,site,"AveragedHoursProp_TimeSeries_StackedGroups.png",sep="")
ggsave(fig1)
}
#plot data grouped with ITS as proportion of hours per day with clicks
title1 = paste(site,"Yearly Average of Proportion of Hours per Day with Clicks - Time Series (ITS)")
plot1 = ggplot(GroupedYearF, aes(x=Day,y=HoursPropFE))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot2 = ggplot(GroupedYearJ, aes(x=Day,y=HoursPropJU))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot3 = ggplot(GroupedYearM, aes(x=Day,y=HoursPropMA))+
geom_bar(stat = "identity")+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "),align = "v",ncol = 1, nrow = 3)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 14), bottom = text_grob("Time (years)"),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90))
fig1 =paste(saveDir,site,"AveragedHoursProp_TimeSeriesITS_StackedGroups.png",sep="")
ggsave(fig1)
if (nrow(oneyear) >= 365) {
#plot data as time series with error bars
title4 = paste(site,"Yearly Average of Proportion of Hours per Day with Clicks - Time Series")
plot1 = ggplot(oneyearF, aes(x=Day,y=HoursPropFE))+
geom_errorbar(aes(ymin = HoursPropFE - SEM, ymax = HoursPropFE + SEM))+
geom_line()+
geom_point()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot2 = ggplot(oneyearJ, aes(x=Day,y=HoursPropJU))+
geom_errorbar(aes(ymin = HoursPropJU - SEM, ymax = HoursPropJU + SEM))+
geom_line()+
geom_point()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
plot3 = ggplot(oneyearM, aes(x=Day,y=HoursPropMA))+
geom_errorbar(aes(ymin = HoursPropMA - SEM, ymax = HoursPropMA + SEM))+
geom_line()+
geom_point()+
theme(axis.title.x = element_blank())+
theme(axis.title.y = element_blank())
figure = ggarrange(plot1,plot2,plot3, labels = c("Social Units","  Mid-Size  ","    Males   "),align = "v",ncol = 1, nrow = 3)
annotate_figure(figure, top = text_grob(title1, face = "bold", size = 14), bottom = text_grob("Time (years)"),
left = text_grob("Proportion of Hours/Day w/Clicks", rot = 90))
fig5 =paste(saveDir,site,"AveragedHoursProp_TimeSeries_ErrorBars_StackedGroups.png",sep="")
ggsave(fig5)
}
